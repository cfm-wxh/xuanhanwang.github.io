---
layout: default
title: Xuanhan Wang, UESTC
---

		<div class="blurb">
			<h3>Dr. Xuanhan Wang (王轩瀚) from UESTC!</h3>
			<p><img src="1.png" alt="photo" style="width:190px;height:190px;float:left;margin-right:35px;">
				<ul class="contacts">
					<li> School of Computer Science and Engineering</li>
					<li>University of Electronic Science and Technology of China</li>
					<li>2006 Xiyuan Ave., West Hi-Tech Zone, Chengdu, China </li>
					<li>Innovation center, Qingshuihe Campus</li>
					<li> <b>LAB</b>: Center for Future Media</li>
					<li> <b>Email</b>: wxuanhan@hotmail.com </li>
					<li><a href="https://scholar.google.com/citations?user=zsm2dpYAAAAJ&hl=en"><div style="color:blue;"> Google Scholar Citation </div></a></li>
					<li><a href="https://stoa-xh91.github.io/"><iv style="color:blue;">Personal Page </div> </a></li>
				</ul>
			</p>
			</div> 

<div class="about">
	
	<p>I'm a PhD student at School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC), under the supervision of&nbsp;</font>
	<a href="https://lianligao.github.io/">
	<font color="#0000ff">Prof. Lianli Gao</font></a>
	&nbsp;and &nbsp;<a href="https://lianligao.github.io/"><font color="#0000ff">Prof. Jingkuan Song</font></a>. 
	I obtained my Master degree in Computer Science from UESTC in 2017, under the supervision of&nbsp;</font> 
	<a href="https://lianligao.github.io/">
	<font color="#0000ff">Prof. Lianli Gao</font></a>.&nbsp; I&nbsp;received my BS degree in Software Engineering from UESTC, in 2014.&nbsp;</font></p>

	<p><font color="#000000"><font>My research interet includes large-scale human-centric recognition, such as human pose estimation, human surface understanding, human action recognition, and the related practical applications etc.&nbsp; Specifically, I am mainly focusing on human pose estimation&nbsp;for Human-centric Visual Content Understanding.&nbsp;</font></font></p>

<h4> Recent News</h4>
	<ul>
	<li>[2020/07/25] 1 paper accepted by ACM MM 2020 </li>
	<li>[2020/05/25] 3 papers submitted to ACM MM 2020 </li>
	<li>[2020/01/25] 1 paper submitted to TPAMI 2020</li>
	<li>[2019/05/25] 2 papers accepted by ACM MM 2019</li>
	</ul>

<h4>Working Experience</h4>
<ul>
	<li>PhD student, School of Computer Science and Engineering,&nbsp;<font color="#0000ff">UESTC</font><font color="#000000">,&nbsp;2019.09-Present</font></li>
	<li><font><font color="#000000">Algorithm Engineer,&nbsp;Institute of HIKVISION Research, </font><font color="#0000ff">HIKVISION</font><font color="#000000">,&nbsp;</font></font><font color="#000000" >2017-2019</font></li>
</ul>


<h4>Publications</h4>
	<ul>
		<li><font ><font color="#000000"><b><font color="#000000">Xuanhan Wang</b><font color="#000000">, Lianli Gao, Jingkuan Song, Heng Tao Shen: KTN: Knowledge Transfer Network for Multi-person DensePose Estimation. ACM Multimedia 2020 [</font><a href="https://github.com/stoa-xh91/KTN" rel="nofollow"><font color="#9900ff">code</font></a><font color="#000000">] [<a href="https://arxiv.org/abs/1701.07901" rel="nofollow">Paper</a>]</font></font></li>
		<li><font ><font color="#000000">Lianli Gao, <b><font color="#000000">Xuanhan Wang</b><font color="#000000">, Jingkuan Song, Yang Liu: Fused GRU with semantic-temporal attention for video captioning. Neurocomputing 395: 222-228 [</font><a href="https://github.com/wangxuanhan/stafg-capgen-vid" rel="nofollow"><font color="#9900ff">code</font></a><font color="#000000">] [Paper]</font></font></li>
		<li><font ><font color="#000000">Xiangpeng Li, Lianli Gao, <b><font color="#000000">Xuanhan Wang</b><font color="#000000">, Wu Liu, Xing Xu, Heng Tao Shen, Jingkuan Song: Learnable Aggregating Net with Diversity Learning for Video Question Answering. ACM Multimedia 2019: 1166-1174 [</font><a href="https://github.com/hetaoconquer/DRH" rel="nofollow"><font color="#9900ff">code</font></a><font color="#000000">] [<a href="https://arxiv.org/abs/1701.07901" rel="nofollow">Paper</a>]</font></font></li>
		<li><font ><font color="#000000">Yuyu Guo, Lianli Gao, Jingkuan Song, Peng Wang, Wuyuan Xie, Heng Tao Shen: Adaptive Multi-Path Aggregation for Human DensePose Estimation in the Wild. ACM Multimedia 2019: 356-364 [</font><a href="https://github.com/hetaoconquer/DRH" rel="nofollow"><font color="#9900ff">code</font></a><font color="#000000">] [<a href="https://arxiv.org/abs/1701.07901" rel="nofollow">Paper</a>]</font></font></li>
		<li><font ><font color="#000000"><b><font color="#000000">Xuanhan Wang</b><font color="#000000">, Lianli Gao, Jingkuan Song, Xiantong Zhen, Nicu Sebe, Heng Tao Shen: Deep appearance and motion learning for egocentric activity recognition. Neurocomputing 275: 438-447 (2018) [<a href="http://dl.acm.org/citation.cfm?id=2967242" rel="nofollow">paper</a>]</font></font></li>
		<li><font ><font color="#000000"><b><font color="#000000">Xuanhan Wang</b><font color="#000000">, Lianli Gao, Peng Wang, Xiaoshuai Sun, Xianglong Liu: Two-Stream 3-D convNet Fusion for Action Recognition in Videos With Arbitrary Size and Length. IEEE Trans. Multimedia 20(3): 634-644 (2018) [paper]</font></font></li>
		<li><font ><font color="#000000"><b><font color="#000000">Xuanhan Wang</b><font color="#000000">, Lianli Gao, Jingkuan Song, Heng Tao Shen: Beyond Frame-level CNN: Saliency-Aware 3-D CNN With LSTM for Video Action Recognition. IEEE Signal Process. Lett. 24(4): 510-514 (2017) [paper]</font></font></li>
	</ul>
	

</div>
